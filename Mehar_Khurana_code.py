# -*- coding: utf-8 -*-
"""Mehar_Khurana_code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vBG-VKxslg_O6TER1EmnPor7WSO_S65Y

# **importing data**
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn import svm
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV 
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
# %matplotlib inline

"""# **importing and splitting**"""

dataset=pd.read_csv('Train_Data.csv')
Train_Data=pd.read_csv('Train_Data.csv')
Traindata_classlabels=pd.read_csv('Traindata_classlabels.csv')
Train_Data_train, Train_Data_test, Traindata_classlabels_train, Traindata_classlabels_test = train_test_split(Train_Data, Traindata_classlabels, test_size=0.3, random_state=53)

"""# **Data set visualization**"""

dataset.head()

dataset.isnull().sum()

dataset.info()

dataset.describe()

plt.figure(figsize=(20,20))
sns.heatmap(dataset.corr(),annot=True)
plt.show()

"""# **training data**

# **K Nearest Neighbours**
"""

clf = KNeighborsClassifier()
clf_parameters = {
            'n_neighbors' : [5,7,9,11,13,15,16,17,18,19],
            'weights' : ['uniform','distance'],
            'metric' : ['minkowski','euclidean','manhattan']
            } 
grid_search = GridSearchCV(estimator=clf,param_grid=clf_parameters,scoring='f1_macro',cv=5)
grid_search.fit(Train_Data_train,Traindata_classlabels_train)
print(grid_search.best_estimator_)
print("kNN score = ")
grid_search.best_estimator_.score(Train_Data_test,Traindata_classlabels_test)

pred = grid_search.best_estimator_.predict(Train_Data_test)
pred_acc = accuracy_score(Traindata_classlabels_test,pred)
pred_f = f1_score(Traindata_classlabels_test,pred,average='macro')
pred_p = precision_score(Traindata_classlabels_test,pred,average='macro')
pred_r = recall_score(Traindata_classlabels_test,pred,average='macro')
print(grid_search.best_estimator_)
print("prediction accuracy = "+str(pred_acc))
print("prediction f measure = "+str(pred_f))
print("prediction Precision= "+str(pred_p))
print("prediction Recall = "+str(pred_r))
print(confusion_matrix(pred,Traindata_classlabels_test))

"""# **Decision Tree**"""

clf = DecisionTreeClassifier(random_state=40) 
clf_parameters = {
            'criterion':('gini', 'entropy'), 
            'max_features':('auto', 'sqrt', 'log2',None),
            'max_depth':(15,30,45,60),
            'ccp_alpha':(0.009,0.005,0.05)
            } 
grid_search = GridSearchCV(estimator=clf,param_grid=clf_parameters,scoring='f1_macro',cv=5)
grid_search.fit(Train_Data_train,Traindata_classlabels_train)
print(grid_search.best_estimator_)
print("Decision tree score = ")
grid_search.best_estimator_.score(Train_Data_test,Traindata_classlabels_test)

pred = grid_search.best_estimator_.predict(Train_Data_test)
pred_acc = accuracy_score(Traindata_classlabels_test,pred)
pred_f = f1_score(Traindata_classlabels_test,pred,average='macro')
pred_p = precision_score(Traindata_classlabels_test,pred,average='macro')
pred_r = recall_score(Traindata_classlabels_test,pred,average='macro')
print(grid_search.best_estimator_)
print("prediction accuracy = "+str(pred_acc))
print("prediction f measure = "+str(pred_f))
print("prediction Precision= "+str(pred_p))
print("prediction Recall = "+str(pred_r))
print(confusion_matrix(pred,Traindata_classlabels_test))

"""# **Random forest classifier**"""

clf = RandomForestClassifier(n_estimators=200)
clf_parameters = {
            'criterion':('entropy','gini'), 
            'max_features':('auto', 'sqrt', 'log2',None),      
            'n_estimators': [int(x) for x in np.linspace(start = 200, stop = 300, num = 100)],
            'max_depth':(10,20,30,50,100,200)
            } 
grid_search = GridSearchCV(estimator=clf,param_grid=clf_parameters,scoring='f1_macro',cv=5)
grid_search.fit(Train_Data_train,Traindata_classlabels_train)
print(grid_search.best_estimator_)
print("random forest score = ")
grid_search.best_estimator_.score(Train_Data_test,Traindata_classlabels_test)

pred = grid_search.best_estimator_.predict(Train_Data_test)
pred_acc = accuracy_score(Traindata_classlabels_test,pred)
pred_f = f1_score(Traindata_classlabels_test,pred,average='macro')
pred_p = precision_score(Traindata_classlabels_test,pred,average='macro')
pred_r = recall_score(Traindata_classlabels_test,pred,average='macro')
print(grid_search.best_estimator_)
print("prediction accuracy = "+str(pred_acc))
print("prediction f measure = "+str(pred_f))
print("prediction Precision= "+str(pred_p))
print("prediction Recall = "+str(pred_r))
print(confusion_matrix(pred,Traindata_classlabels_test))

"""# **Gaussian Naive bayes**"""

clf = GaussianNB()
clf_parameters = {
            'var_smoothing':np.linspace(0,-13,num=100)
            }
grid_search = GridSearchCV(estimator=clf,param_grid=clf_parameters,scoring='f1_macro',cv=5)
grid_search.fit(Train_Data_train,Traindata_classlabels_train)
print(grid_search.best_estimator_)
print("gaussian score = ")
grid_search.best_estimator_.score(Train_Data_test,Traindata_classlabels_test)

pred = grid_search.best_estimator_.predict(Train_Data_test)
pred_acc = accuracy_score(Traindata_classlabels_test,pred)
pred_f = f1_score(Traindata_classlabels_test,pred,average='macro')
pred_p = precision_score(Traindata_classlabels_test,pred,average='macro')
pred_r = recall_score(Traindata_classlabels_test,pred,average='macro')
print(grid_search.best_estimator_)
print("prediction accuracy = "+str(pred_acc))
print("prediction f measure = "+str(pred_f))
print("prediction Precision= "+str(pred_p))
print("prediction Recall = "+str(pred_r))
print(confusion_matrix(pred,Traindata_classlabels_test))

"""# **Support vector machine**"""

clf = svm.SVC(class_weight='balanced',probability=True)
clf_parameters = {
            'C':np.logspace(-2,7,num=25,base=2),
            'gamma': [1,0.1,0.01,0.001],
            'kernel':('linear','rbf','polynomial','sigmoid')
            }
grid_search = GridSearchCV(estimator=clf,param_grid=clf_parameters,scoring='f1_macro',cv=5)
grid_search.fit(Train_Data_train,Traindata_classlabels_train)
print(grid_search.best_estimator_)
print("svm score = ")
grid_search.best_estimator_.score(Train_Data_test,Traindata_classlabels_test)

pred = grid_search.best_estimator_.predict(Train_Data_test)
pred_acc = accuracy_score(Traindata_classlabels_test,pred)
pred_f = f1_score(Traindata_classlabels_test,pred,average='macro')
pred_p = precision_score(Traindata_classlabels_test,pred,average='macro')
pred_r = recall_score(Traindata_classlabels_test,pred,average='macro')
print(grid_search.best_estimator_)
print("prediction accuracy = "+str(pred_acc))
print("prediction f measure = "+str(pred_f))
print("prediction Precision= "+str(pred_p))
print("prediction Recall = "+str(pred_r))
print(confusion_matrix(pred,Traindata_classlabels_test))

print(grid_search.best_estimator_)

"""# **Logistic regression**"""

clf = LogisticRegression(multi_class="multinomial",solver="lbfgs")
clf_parameters = {
     "C":np.linspace(start = 0.1, stop = 10, num = 100),
     "penalty":["l1","l2",'elasticnet'],
     'solver':['newton-cg','lbfgs','liblinear']}
grid_search = GridSearchCV(estimator=clf,param_grid=clf_parameters,scoring='f1_macro',cv=5)
grid_search.fit(Train_Data_train,Traindata_classlabels_train)
print(grid_search.best_estimator_)
print("logistic regression score = ")
grid_search.best_estimator_.score(Train_Data_test,Traindata_classlabels_test)

# l1 lasso l2 ridge

pred = grid_search.best_estimator_.predict(Train_Data_test)
pred_acc = accuracy_score(Traindata_classlabels_test,pred)
pred_f = f1_score(Traindata_classlabels_test,pred,average='macro')
pred_p = precision_score(Traindata_classlabels_test,pred,average='macro')
pred_r = recall_score(Traindata_classlabels_test,pred,average='macro')
print(grid_search.best_estimator_)
print("prediction accuracy = "+str(pred_acc))
print("prediction f measure = "+str(pred_f))
print("prediction Precision= "+str(pred_p))
print("prediction Recall = "+str(pred_r))
print(confusion_matrix(pred,Traindata_classlabels_test))

"""# **Prediction of data**

We have found that the Logistic Regression has the highest f value as compared to other models used in this project. So I am using this model to predict the target values of the test data
"""

Test_Data=pd.read_csv('testdata.csv')
clf=LogisticRegression(C=0.1, multi_class='multinomial',solver='newton-cg')
clf.fit(Train_Data_train,Traindata_classlabels_train)
predict = clf.predict(Test_Data)
predict